{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de47c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61ce73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05a1b63",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c6ead48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "train_file = f'{data_dir}/train/train.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe01ef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_file, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2221ad7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['ar', 'bg', 'de', 'el', 'en', 'es', 'fr', 'hi', 'ru', 'sw', 'th',\n",
       "        'tr', 'ur', 'vi', 'zh'], dtype=object),\n",
       " array([  1000,   1000,   1000,   1000, 100993,   1000,   1000,   1000,\n",
       "          1000,   1000,   1000,   1000,   1000,   1000,   1000]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['language'].values, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe5a5aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['zh', 'hi', 'sw', 'es']\n",
    "\n",
    "lang_list = []\n",
    "for l in languages:\n",
    "    lang_list.append(df[df['language'] == l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67fa988b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "这是一项光荣的服务。\n",
      "这是一项光荣的服务，因为它关乎挽救生命。\n",
      "zh\n",
      "\n",
      "entailment\n",
      "saath hi, kaise unka rahna mujhe madat kar sakta hai? aur jis tarah Pitt ne use javab nahi diya: tu dekh? usne sir hilate hue kaha\n",
      "उसने स्वीकृति के संकेत में अपना कंधा हिलाया था |\n",
      "hi\n",
      "\n",
      "contradiction\n",
      "Kuna jambo la kushtua linalomngoja mwongo huyu katika pwani ya Royal. Damu ingekuwa imeingilia kati kwa hio, bali Julian alimzuia.\n",
      "Blood ni kikundi cha kimataifa cha wahalifu kilicho na msingi Port Royal ambako Bwana Julian anafanya mikataba isio na kusudi halali.\n",
      "sw\n",
      "\n",
      "entailment\n",
      "No se molestó en levantarse, ni siquiera cuando Lord Julian, obedeciendo a los instintos de una mejor crianza, le dio ejemplo.\n",
      "Lord Julian se levantó, mostrando buenos modales, pero no se molestó en ponerse de pie.\n",
      "es\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c, l in zip(languages, lang_list):\n",
    "    p = np.random.randint(len(l))\n",
    "    x = l.iloc[p]\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        print(x[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7388587",
   "metadata": {},
   "source": [
    "## XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "113e9ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import XLMTokenizer, XLMWithLMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "291f520f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 5.60M/5.60M [00:02<00:00, 1.98MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 2.99M/2.99M [00:02<00:00, 1.14MB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 446/446 [00:00<00:00, 387kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 10.8k/10.8k [00:00<00:00, 7.15MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 1.14G/1.14G [00:15<00:00, 73.7MB/s]\n",
      "Some weights of XLMWithLMHeadModel were not initialized from the model checkpoint at xlm-mlm-17-1280 and are newly initialized: ['transformer.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = XLMTokenizer.from_pretrained(\"xlm-mlm-17-1280\")\n",
    "model = XLMWithLMHeadModel.from_pretrained(\"xlm-mlm-17-1280\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2f57c13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 0, 'fr': 1}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.lang2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d4bb4ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([tokenizer.encode(\"Wikipedia was used to\")]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "04ab363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_id = tokenizer.lang2id[\"en\"]  # 0\n",
    "langs = torch.tensor([language_id] * input_ids.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "abf762be",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = langs.view(1, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "712f419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(input_ids, langs=langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e9800562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ -6.3665,  10.7176,  -6.3754,  ...,  -6.1219,  -6.3775,  -6.0470],\n",
       "         [-13.8973,  -3.1509, -13.8749,  ..., -14.6975, -12.9415, -13.8252],\n",
       "         [ -9.2461,   4.8444,  -9.6047,  ..., -10.5616,  -8.2646,  -9.9838],\n",
       "         ...,\n",
       "         [-12.1487,   9.7573, -12.0884,  ..., -13.0167, -11.7700, -10.6408],\n",
       "         [-11.5067,   4.1504, -11.6619,  ..., -12.0130, -11.2718, -10.8311],\n",
       "         [ -8.4061,   6.6820,  -8.5521,  ...,  -8.2401,  -8.5305,  -8.3125]]],\n",
       "       grad_fn=<AddBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93655b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
